{"code":"(window.webpackJsonp=window.webpackJsonp||[]).push([[71],{655:function(s,a,t){\"use strict\";t.r(a);var n=t(10),e=Object(n.a)({},(function(){var s=this,a=s.$createElement,t=s._self._c||a;return t(\"ContentSlotsDistributor\",{attrs:{\"slot-key\":s.$parent.slotKey}},[t(\"p\",[s._v(\"Scrapy 是一个强大的开源爬虫框架，它能够帮助开发者高效地抓取网站数据，并从中提取结构化信息。它基于 Python 开发，使用 Twisted 库来处理异步网络请求，使得它非常适合进行大规模的数据抓取。本教程将指导你如何在本地环境中设置 Scrapy、创建一个新的爬虫项目，并提取特定网站的数据。\")]),s._v(\" \"),t(\"h2\",{attrs:{id:\"安装-scrapy\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#安装-scrapy\"}},[s._v(\"#\")]),s._v(\" 安装 Scrapy\")]),s._v(\" \"),t(\"p\",[s._v(\"在开始之前，你需要确保你的机器上已经安装了 Python 环境。Scrapy 支持 Python 3.5 及以上版本。可以使用 pip 来安装 Scrapy：\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"pip \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"install\")]),s._v(\" scrapy\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"创建-scrapy-项目\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#创建-scrapy-项目\"}},[s._v(\"#\")]),s._v(\" 创建 Scrapy 项目\")]),s._v(\" \"),t(\"p\",[s._v(\"安装完 Scrapy 后，可以通过以下命令来创建一个新的项目：\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"scrapy startproject myproject\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"p\",[s._v('将 \"myproject\" 替换为你的想要的项目名。此命令会在当前目录下创建一系列项目文件和目录，其结构如下所示：')]),s._v(\" \"),t(\"div\",{staticClass:\"language- line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-text\"}},[t(\"code\",[s._v(\"myproject/\\n    scrapy.cfg            # 配置文件\\n    myproject/            # 项目的 Python 模块，用于引用代码\\n        __init__.py\\n        items.py          # 项目 item 文件\\n        middlewares.py    # 项目中间件文件\\n        pipelines.py      # 项目管道文件\\n        settings.py       # 项目设置文件\\n        spiders/          # 存放爬虫的目录\\n            __init__.py\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"构建-spiders\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#构建-spiders\"}},[s._v(\"#\")]),s._v(\" 构建 Spiders\")]),s._v(\" \"),t(\"p\",[s._v(\"Spider 是 Scrapy 用来抓取网站数据的类。每个 Spider 类将定义要抓取的 URL 列表及如何从页面抓取数据。\")]),s._v(\" \"),t(\"p\",[s._v(\"首先，在 \"),t(\"code\",[s._v(\"spiders\")]),s._v(\" 目录下创建一个 Python 文件，命名为 \"),t(\"code\",[s._v(\"my_spider.py\")]),s._v(\"。在该文件中，定义你的爬虫：\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-python line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-python\"}},[t(\"code\",[t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"import\")]),s._v(\" scrapy\\n\\n\"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"class\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token class-name\"}},[s._v(\"MySpider\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"scrapy\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\".\")]),s._v(\"Spider\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\"\\n    name \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"myproject\"')]),s._v(\"\\n    allowed_domains \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"www.example.net\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n    start_urls \"),t(\"span\",{pre:!0,attrs:{class:\"token operator\"}},[s._v(\"=\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"[\")]),t(\"span\",{pre:!0,attrs:{class:\"token string\"}},[s._v('\"https://www.example.net/\"')]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"]\")]),s._v(\"\\n\\n    \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"def\")]),s._v(\" \"),t(\"span\",{pre:!0,attrs:{class:\"token function\"}},[s._v(\"parse\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\"(\")]),s._v(\"self\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\",\")]),s._v(\" response\"),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\")\")]),t(\"span\",{pre:!0,attrs:{class:\"token punctuation\"}},[s._v(\":\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token comment\"}},[s._v(\"# 在这里编写提取逻辑\")]),s._v(\"\\n        \"),t(\"span\",{pre:!0,attrs:{class:\"token keyword\"}},[s._v(\"pass\")]),s._v(\"\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"2\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"3\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"4\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"5\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"6\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"7\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"8\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"9\")]),t(\"br\"),t(\"span\",{staticClass:\"line-number\"},[s._v(\"10\")]),t(\"br\")])]),t(\"h2\",{attrs:{id:\"运行你的-scrapy-爬虫\"}},[t(\"a\",{staticClass:\"header-anchor\",attrs:{href:\"#运行你的-scrapy-爬虫\"}},[s._v(\"#\")]),s._v(\" 运行你的 Scrapy 爬虫\")]),s._v(\" \"),t(\"p\",[s._v(\"完成爬虫代码编写后，可以通过以下命令来运行它：\")]),s._v(\" \"),t(\"div\",{staticClass:\"language-bash line-numbers-mode\"},[t(\"pre\",{pre:!0,attrs:{class:\"language-bash\"}},[t(\"code\",[s._v(\"scrapy crawl myproject -o output.json\\n\")])]),s._v(\" \"),t(\"div\",{staticClass:\"line-numbers-wrapper\"},[t(\"span\",{staticClass:\"line-number\"},[s._v(\"1\")]),t(\"br\")])]),t(\"p\",[s._v('此命令会启动名为 \"myproject\" 的爬虫，开始从指定的 URL '),t(\"code\",[s._v(\"https://www.example.net/\")]),s._v(\" 抓取数据，并将抓取到的数据保存到 \"),t(\"code\",[s._v(\"output.json\")]),s._v(\" 文件中。\")]),s._v(\" \"),t(\"p\",[s._v(\"通过以上步骤，你可以开始你的 Scrapy 爬虫项目，用于抓取和分析网站数据。随着经验的积累，你可以进一步学习如何优化爬虫处理更复杂的数据提取任务。\")])])}),[],!1,null,null,null);a.default=e.exports}}]);","extractedComments":[]}